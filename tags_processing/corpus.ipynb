{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take tags only from test5 database\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test5_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete all data with empty tags from test data\n",
    "test_data.dropna(subset=['photoTags'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take tags from the column 'photoTags'\n",
    "tags = test_data.loc[:,'photoTags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join them to list\n",
    "text = ' '.join(test_data['photoTags'])\n",
    "text_list = text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<216987x185595 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1762366 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185595\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the corpus into the file\n",
    "import csv\n",
    "\n",
    "dt = vectorizer.vocabulary_\n",
    "\n",
    "\n",
    "d = pd.DataFrame.from_dict(dt, orient='index', dtype=None)\n",
    "\n",
    "d.to_csv(\"corpus1.csv\", encoding=\"utf-8\", header=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "train = pd.read_csv(\"corpus1.csv\");\n",
    "\n",
    "#CLEAN DATA\n",
    "train['words'] = train['words'].str.replace(\"\\d+\", '')\n",
    "train['words'] = train['words'].str.replace(\"sec\", '')\n",
    "train['words'] = train['words'].str.replace(\"nabkv\", '')\n",
    "\n",
    "#train['words'] = train['words'].str.replace(\"^[0-9]*$\", '')\n",
    "#s = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", s)\n",
    "train['words'].replace('', np.nan, inplace=True)\n",
    "train = train.dropna(subset=['words'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['words'].str.len() > 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "train.to_csv(\"corpus.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data again \n",
    "test_data = pd.read_csv('corpus.csv')\n",
    "#take tags from the column 'photoTags'\n",
    "tags = test_data.loc[:,'words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we have features \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tf_matrix = tfidf.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have sparse matrix for 3 mln pictures \n",
    "# create KNN\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data_ = train_data.loc[:,'photoTags']\n",
    "_vect = TfidfVectorizer(vocabulary = vocab)\n",
    "train_c_matrix = _vect.fit_transform(train_data_)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors = 1).fit(train_c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test5_all.csv')\n",
    "# delete all data with empty tags from test data\n",
    "test_data.dropna(subset=['photoTags'], inplace=True)\n",
    "test_data_ = test_data.loc[:,'photoTags']\n",
    "new_vect = TfidfVectorizer(vocabulary = vocab)\n",
    "test_c_matrix = new_vect.fit_transform(test_data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70794809]] [[309402]]\n"
     ]
    }
   ],
   "source": [
    "distances, indices = nbrs.kneighbors(test_c_matrix[3])\n",
    "print(distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309402\n"
     ]
    }
   ],
   "source": [
    "i = indices[0][0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.275\n",
      "0.5225\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[i,'latitude'])\n",
    "print(train_data.loc[i,'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadband carphonewarehouse\n"
     ]
    }
   ],
   "source": [
    "print(train_data.loc[i,'photoTags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_data.loc[i,'photoTags'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
