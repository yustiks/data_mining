{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31180\n",
      "26908\n"
     ]
    }
   ],
   "source": [
    "#take tags only from test5 database\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#df = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test2_all.csv')\n",
    "\n",
    "# delete all data with empty tags from test data\n",
    "test_data.dropna(subset=['photoTags'], inplace=True)\n",
    "\n",
    "#take tags from the column 'photoTags'\n",
    "tags = test_data.loc[:,'photoTags']\n",
    "\n",
    "# join them to list\n",
    "text = ' '.join(test_data['photoTags'])\n",
    "text_list = text.split(' ')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(tags)\n",
    "\n",
    "\n",
    "\n",
    "print(len(vectorizer.vocabulary_))\n",
    "\n",
    "\n",
    "# save the corpus into the file\n",
    "import csv\n",
    "\n",
    "dt = vectorizer.vocabulary_\n",
    "\n",
    "\n",
    "d = pd.DataFrame.from_dict(dt, orient='index', dtype=None)\n",
    "\n",
    "d.to_csv(\"corpus1.csv\", encoding=\"utf-8\", header=None)\n",
    "\n",
    "#LOAD DATA\n",
    "crp = pd.read_csv(\"corpus1.csv\", header=None)\n",
    "crp.to_csv(\"corpus1.csv\", encoding=\"utf-8\", header=['words','id'], index=None)\n",
    "\n",
    "#LOAD DATA\n",
    "crp = pd.read_csv(\"corpus1.csv\")\n",
    "\n",
    "#CLEAN DATA\n",
    "crp['words'] = crp['words'].str.replace(\"\\d+\", '')\n",
    "crp['words'] = crp['words'].str.replace(\"sec\", '')\n",
    "crp['words'] = crp['words'].str.replace(\"nabkv\", '')\n",
    "# delete values less then 3\n",
    "crp =crp[crp['words'].str.len() > 3]\n",
    "# delete geolat geolon\n",
    "crp['words'] = crp['words'].str.replace(\"geolat\", '')\n",
    "crp['words'] = crp['words'].str.replace(\"geolon\", '')\n",
    "crp['words'] = crp['words'].str.replace(\"geotagged\", '')\n",
    "\n",
    "#train['words'] = train['words'].str.replace(\"^[0-9]*$\", '')\n",
    "#s = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", s)\n",
    "crp['words'].replace('', np.nan, inplace=True)\n",
    "crp = crp.dropna(subset=['words'])\n",
    "\n",
    "crp = crp[crp['words'].str.len() > 3]\n",
    "\n",
    "# save data\n",
    "crp.to_csv(\"corpus.csv\", encoding=\"utf-8\",index=None)\n",
    "\n",
    "# load data again \n",
    "crp = pd.read_csv('corpus.csv')\n",
    "#take tags from the column 'photoTags'\n",
    "tags = crp.loc[:,'words']\n",
    "\n",
    "# so we have features \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tf_matrix = tfidf.fit_transform(tags)\n",
    "\n",
    "vocab = tfidf.vocabulary_\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have sparse matrix for 3 mln pictures \n",
    "# create KNN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "train_data = pd.read_csv('dm_clean1.csv')\n",
    "train_data_ = train_data.loc[:,'photoTags']\n",
    "_vect = TfidfVectorizer(vocabulary = vocab)\n",
    "train_c_matrix = _vect.fit_transform(train_data_)\n",
    "\n",
    "#nbrs = NearestNeighbors(n_neighbors = 1, algorithm='ball_tree')\n",
    "#nbrs.fit(train_c_matrix)\n",
    "\n",
    "test_data = pd.read_csv('test2_all.csv')\n",
    "# delete all data with empty tags from test data\n",
    "#test_data.dropna(subset=['photoTags'], inplace=True)\n",
    "test_data['photoTags'].replace( np.nan,'', inplace=True)\n",
    "test_data_ = test_data.loc[:,'photoTags']\n",
    "new_vect = TfidfVectorizer(vocabulary = vocab)\n",
    "test_c_matrix = new_vect.fit_transform(test_data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensionality reduction \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=20, n_iter=7, random_state=42)\n",
    "svd_test_matrix = svd.fit_transform(test_c_matrix)\n",
    "svd_train_matrix = svd.fit_transform(train_c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=2, metric='manhattan',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=1, p=2, radius=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors = 1, algorithm='ball_tree', metric='manhattan', leaf_size=2)\n",
    "nbrs.fit(svd_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py:211: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=2, metric='manhattan',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=1, p=2, radius=1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors = 1, algorithm='ball_tree', metric='manhattan', leaf_size=2)\n",
    "nbrs.fit(train_c_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BallTree for faster \n",
    "from sklearn.neighbors import KDTree\n",
    "tree = KDTree( train_c_matrix, leaf_size = 3, metric='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 11:35:48.443557\n",
      "0\n",
      "2018-05-16 11:35:48.453558\n",
      "100\n",
      "2018-05-16 11:35:50.003634\n",
      "200\n",
      "2018-05-16 11:35:51.583684\n",
      "300\n",
      "2018-05-16 11:35:53.763732\n",
      "400\n",
      "2018-05-16 11:35:55.303783\n",
      "500\n",
      "2018-05-16 11:35:57.353873\n",
      "600\n",
      "2018-05-16 11:35:58.953902\n",
      "700\n",
      "2018-05-16 11:36:00.663983\n",
      "800\n",
      "2018-05-16 11:36:02.294035\n",
      "900\n",
      "2018-05-16 11:36:04.054070\n",
      "1000\n",
      "2018-05-16 11:36:05.524140\n",
      "1100\n",
      "2018-05-16 11:36:07.024189\n",
      "1200\n",
      "2018-05-16 11:36:08.584241\n",
      "1300\n",
      "2018-05-16 11:36:10.214288\n",
      "1400\n",
      "2018-05-16 11:36:11.704342\n",
      "1500\n",
      "2018-05-16 11:36:13.604402\n",
      "1600\n",
      "2018-05-16 11:36:15.264460\n",
      "1700\n",
      "2018-05-16 11:36:16.834510\n",
      "1800\n",
      "2018-05-16 11:36:18.244532\n",
      "1900\n",
      "2018-05-16 11:36:19.774603\n",
      "2000\n",
      "2018-05-16 11:36:21.234631\n",
      "2100\n",
      "2018-05-16 11:36:23.024689\n",
      "2200\n",
      "2018-05-16 11:36:24.474761\n",
      "2300\n",
      "2018-05-16 11:36:25.844803\n",
      "2400\n",
      "2018-05-16 11:36:27.304848\n",
      "2500\n",
      "2018-05-16 11:36:28.624872\n",
      "2600\n",
      "2018-05-16 11:36:29.854936\n",
      "2700\n",
      "2018-05-16 11:36:31.554992\n",
      "2800\n",
      "2018-05-16 11:36:32.995016\n",
      "2900\n",
      "2018-05-16 11:36:34.555066\n",
      "3000\n",
      "2018-05-16 11:36:36.175119\n",
      "3100\n",
      "2018-05-16 11:36:38.085182\n",
      "3200\n",
      "2018-05-16 11:36:40.265277\n",
      "3300\n",
      "2018-05-16 11:36:41.835329\n",
      "3400\n",
      "2018-05-16 11:36:43.705384\n",
      "3500\n",
      "2018-05-16 11:36:45.365419\n",
      "3600\n",
      "2018-05-16 11:36:47.044421\n",
      "3700\n",
      "2018-05-16 11:36:48.864456\n",
      "3800\n",
      "2018-05-16 11:36:50.714540\n",
      "3900\n",
      "2018-05-16 11:36:52.164585\n",
      "4000\n",
      "2018-05-16 11:36:53.774636\n",
      "4100\n",
      "2018-05-16 11:36:55.402694\n",
      "4200\n",
      "2018-05-16 11:36:56.812733\n",
      "4300\n",
      "2018-05-16 11:36:58.622801\n",
      "4400\n",
      "2018-05-16 11:37:00.242851\n",
      "4500\n",
      "2018-05-16 11:37:01.782898\n",
      "4600\n",
      "2018-05-16 11:37:03.342952\n",
      "4700\n",
      "2018-05-16 11:37:04.893006\n",
      "4800\n",
      "2018-05-16 11:37:06.393029\n",
      "4900\n",
      "2018-05-16 11:37:08.044461\n",
      "5000\n",
      "2018-05-16 11:37:09.831207\n",
      "5100\n",
      "2018-05-16 11:37:11.691271\n",
      "5200\n",
      "2018-05-16 11:37:13.061313\n",
      "5300\n",
      "2018-05-16 11:37:14.621342\n",
      "5400\n",
      "2018-05-16 11:37:16.141413\n",
      "5500\n",
      "2018-05-16 11:37:17.731461\n",
      "5600\n",
      "2018-05-16 11:37:19.261516\n",
      "5700\n",
      "2018-05-16 11:37:21.031816\n",
      "5800\n",
      "2018-05-16 11:37:22.531835\n",
      "5900\n",
      "2018-05-16 11:37:24.051907\n",
      "6000\n",
      "2018-05-16 11:37:25.621961\n",
      "6100\n",
      "2018-05-16 11:37:27.137585\n",
      "6200\n",
      "2018-05-16 11:37:28.873284\n",
      "6300\n",
      "2018-05-16 11:37:30.393332\n",
      "6400\n",
      "2018-05-16 11:37:31.983361\n",
      "6500\n",
      "2018-05-16 11:37:33.553413\n",
      "6600\n",
      "2018-05-16 11:37:35.483493\n",
      "6700\n",
      "2018-05-16 11:37:37.333560\n",
      "6800\n",
      "2018-05-16 11:37:39.143617\n",
      "6900\n",
      "2018-05-16 11:37:40.553642\n",
      "7000\n",
      "2018-05-16 11:37:42.443702\n",
      "7100\n",
      "2018-05-16 11:37:44.023780\n",
      "7200\n",
      "2018-05-16 11:37:45.863838\n",
      "7300\n",
      "2018-05-16 11:37:47.793902\n",
      "7400\n",
      "2018-05-16 11:37:49.593961\n",
      "7500\n",
      "2018-05-16 11:37:51.874012\n",
      "7600\n",
      "2018-05-16 11:37:53.544090\n",
      "7700\n",
      "2018-05-16 11:37:55.544134\n",
      "7800\n",
      "2018-05-16 11:37:57.514710\n",
      "7900\n",
      "2018-05-16 11:37:59.294767\n",
      "8000\n",
      "2018-05-16 11:38:01.134805\n",
      "8100\n",
      "2018-05-16 11:38:03.187365\n",
      "8200\n",
      "2018-05-16 11:38:05.157431\n",
      "8300\n",
      "2018-05-16 11:38:06.647478\n",
      "8400\n",
      "2018-05-16 11:38:08.367535\n",
      "8500\n",
      "2018-05-16 11:38:10.087613\n",
      "8600\n",
      "2018-05-16 11:38:11.727645\n",
      "8700\n",
      "2018-05-16 11:38:13.687363\n",
      "8800\n",
      "2018-05-16 11:38:15.357439\n",
      "8900\n",
      "2018-05-16 11:38:17.227498\n",
      "9000\n",
      "2018-05-16 11:38:19.177560\n",
      "9100\n",
      "2018-05-16 11:38:20.837619\n",
      "9200\n",
      "2018-05-16 11:38:22.587673\n",
      "9300\n",
      "2018-05-16 11:38:24.511668\n",
      "9400\n",
      "2018-05-16 11:38:26.131721\n",
      "9500\n",
      "2018-05-16 11:38:27.969393\n",
      "9600\n",
      "2018-05-16 11:38:29.421822\n",
      "9700\n",
      "2018-05-16 11:38:30.977542\n",
      "9800\n",
      "2018-05-16 11:38:32.657594\n",
      "9900\n",
      "2018-05-16 11:38:34.247648\n",
      "10000\n",
      "2018-05-16 11:38:35.856493\n",
      "10100\n",
      "2018-05-16 11:38:37.374665\n",
      "10200\n",
      "2018-05-16 11:38:39.174718\n",
      "10300\n",
      "2018-05-16 11:38:41.324771\n",
      "10400\n",
      "2018-05-16 11:38:43.397626\n",
      "10500\n",
      "2018-05-16 11:38:45.217691\n",
      "10600\n",
      "2018-05-16 11:38:47.563002\n",
      "10700\n",
      "2018-05-16 11:38:49.313039\n",
      "10800\n",
      "2018-05-16 11:38:51.515976\n",
      "10900\n",
      "2018-05-16 11:38:53.422350\n",
      "11000\n",
      "2018-05-16 11:38:55.242412\n",
      "11100\n",
      "2018-05-16 11:38:57.480465\n",
      "11200\n",
      "2018-05-16 11:38:59.100519\n",
      "11300\n",
      "2018-05-16 11:39:00.910580\n",
      "11400\n",
      "2018-05-16 11:39:03.100651\n",
      "11500\n",
      "2018-05-16 11:39:05.030714\n",
      "11600\n",
      "2018-05-16 11:39:07.210761\n",
      "11700\n",
      "2018-05-16 11:39:09.070847\n",
      "11800\n",
      "2018-05-16 11:39:11.010885\n",
      "11900\n",
      "2018-05-16 11:39:12.840969\n",
      "12000\n",
      "2018-05-16 11:39:14.651026\n",
      "12100\n",
      "2018-05-16 11:39:17.161107\n",
      "12200\n",
      "2018-05-16 11:39:18.669242\n",
      "12300\n",
      "2018-05-16 11:39:20.479325\n",
      "12400\n",
      "2018-05-16 11:39:22.909381\n",
      "12500\n",
      "2018-05-16 11:39:24.518721\n",
      "12600\n",
      "2018-05-16 11:39:26.468786\n",
      "12700\n",
      "2018-05-16 11:39:28.938594\n",
      "12800\n",
      "2018-05-16 11:39:31.228311\n",
      "12900\n",
      "2018-05-16 11:39:32.844854\n",
      "13000\n",
      "2018-05-16 11:39:35.615140\n",
      "13100\n",
      "2018-05-16 11:39:37.635302\n",
      "13200\n",
      "2018-05-16 11:39:39.449328\n",
      "13300\n",
      "2018-05-16 11:39:41.255145\n",
      "13400\n",
      "2018-05-16 11:39:43.125187\n",
      "13500\n",
      "2018-05-16 11:39:45.115276\n",
      "13600\n",
      "2018-05-16 11:39:46.897892\n",
      "13700\n",
      "2018-05-16 11:39:48.564801\n",
      "13800\n",
      "2018-05-16 11:39:50.374335\n",
      "13900\n",
      "2018-05-16 11:39:52.328398\n",
      "14000\n",
      "2018-05-16 11:39:54.105602\n",
      "14100\n",
      "2018-05-16 11:39:55.815652\n",
      "14200\n",
      "2018-05-16 11:39:57.165679\n",
      "14300\n",
      "2018-05-16 11:39:58.825735\n",
      "14400\n",
      "2018-05-16 11:40:00.265779\n",
      "14500\n",
      "2018-05-16 11:40:02.022227\n",
      "14600\n",
      "2018-05-16 11:40:03.513891\n",
      "14700\n",
      "2018-05-16 11:40:05.193960\n",
      "14800\n",
      "2018-05-16 11:40:07.110012\n",
      "14900\n",
      "2018-05-16 11:40:09.164080\n",
      "15000\n",
      "2018-05-16 11:40:11.624157\n",
      "15100\n",
      "2018-05-16 11:40:13.654203\n",
      "15200\n",
      "2018-05-16 11:40:15.686975\n",
      "15300\n",
      "2018-05-16 11:40:17.277839\n",
      "15400\n",
      "2018-05-16 11:40:18.867872\n",
      "15500\n",
      "2018-05-16 11:40:20.297581\n",
      "15600\n",
      "2018-05-16 11:40:21.844100\n",
      "15700\n",
      "2018-05-16 11:40:23.674135\n",
      "15800\n",
      "2018-05-16 11:40:25.526723\n",
      "15900\n",
      "2018-05-16 11:40:26.868211\n",
      "16000\n",
      "2018-05-16 11:40:28.958277\n",
      "16100\n",
      "2018-05-16 11:40:31.138351\n",
      "16200\n",
      "2018-05-16 11:40:32.658401\n",
      "16300\n",
      "2018-05-16 11:40:34.358457\n",
      "16400\n",
      "2018-05-16 11:40:36.558504\n",
      "16500\n",
      "2018-05-16 11:40:39.198591\n",
      "16600\n",
      "2018-05-16 11:40:41.208681\n",
      "16700\n",
      "2018-05-16 11:40:43.058741\n",
      "16800\n",
      "2018-05-16 11:40:44.448762\n",
      "16900\n",
      "2018-05-16 11:40:45.998832\n",
      "17000\n",
      "2018-05-16 11:40:47.498887\n",
      "17100\n",
      "2018-05-16 11:40:48.898929\n",
      "17200\n",
      "2018-05-16 11:40:50.338973\n",
      "17300\n",
      "2018-05-16 11:40:51.899005\n",
      "17400\n",
      "2018-05-16 11:40:53.299076\n",
      "17500\n",
      "2018-05-16 11:40:55.079135\n",
      "17600\n",
      "2018-05-16 11:40:56.329171\n",
      "17700\n",
      "2018-05-16 11:40:57.859201\n",
      "17800\n",
      "2018-05-16 11:40:59.279270\n",
      "17900\n",
      "2018-05-16 11:41:00.709294\n",
      "18000\n",
      "2018-05-16 11:41:02.919387\n",
      "18100\n",
      "2018-05-16 11:41:04.459417\n",
      "18200\n",
      "2018-05-16 11:41:05.879462\n",
      "18300\n",
      "2018-05-16 11:41:07.559521\n",
      "18400\n",
      "2018-05-16 11:41:09.519605\n",
      "18500\n",
      "2018-05-16 11:41:10.899629\n",
      "18600\n",
      "2018-05-16 11:41:12.379699\n",
      "18700\n",
      "2018-05-16 11:41:14.004598\n",
      "18800\n",
      "2018-05-16 11:41:15.564674\n",
      "18900\n",
      "2018-05-16 11:41:16.914716\n",
      "19000\n",
      "2018-05-16 11:41:18.254736\n",
      "19100\n",
      "2018-05-16 11:41:20.344826\n",
      "19200\n",
      "2018-05-16 11:41:21.694850\n",
      "19300\n",
      "2018-05-16 11:41:22.254871\n",
      "19400\n",
      "2018-05-16 11:41:23.934924\n",
      "19500\n",
      "2018-05-16 11:41:26.115012\n",
      "19600\n",
      "2018-05-16 11:41:28.205085\n",
      "19700\n",
      "2018-05-16 11:41:29.845139\n",
      "19800\n",
      "2018-05-16 11:41:32.145189\n",
      "19900\n",
      "2018-05-16 11:41:33.685264\n",
      "20000\n",
      "2018-05-16 11:41:35.245311\n",
      "20100\n",
      "2018-05-16 11:41:39.375426\n",
      "20200\n",
      "2018-05-16 11:41:43.485562\n",
      "20300\n",
      "2018-05-16 11:41:47.575717\n",
      "20400\n",
      "2018-05-16 11:41:51.685854\n",
      "20500\n",
      "2018-05-16 11:41:55.805988\n",
      "20600\n",
      "2018-05-16 11:41:59.926099\n",
      "20700\n",
      "2018-05-16 11:42:04.046254\n",
      "20800\n",
      "2018-05-16 11:42:08.156386\n",
      "20900\n",
      "2018-05-16 11:42:12.276522\n",
      "21000\n",
      "2018-05-16 11:42:16.386637\n",
      "21100\n",
      "2018-05-16 11:42:20.506792\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "predicted_lt = []\n",
    "predicted_lng = []\n",
    "#indexes = []\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "for i in range(0,len(test_data_)):\n",
    "    distances, indices = nbrs.kneighbors(svd_test_matrix[[i]])\n",
    "    \n",
    "    #distances, indices = nbrs.kneighbors(test_c_matrix[i])\n",
    "    #distances, indices = tree.query([svd_test_matrix[i]], k=1)\n",
    "    ind = indices[0][0]\n",
    "    #indexes.append(indices[0][0])\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "        print(datetime.datetime.now())            \n",
    "    #print('ind',ind)\n",
    "    #print(distances)\n",
    "\n",
    "    lt =train_data.loc[ind,'latitude']\n",
    "    predicted_lt.append(lt)\n",
    "    lng = train_data.loc[ind,'longitude']\n",
    "    predicted_lng.append(lng)\n",
    "    \n",
    "\n",
    "    #df_lt = pd.DataFrame([lt], columns=['lt'])\n",
    "    #df_ln = pd.DataFrame([lng], columns=['ln'])\n",
    "    \n",
    "    #data_lt = data_lt.append(df_lt)\n",
    "    #data_ln = data_ln.append(df_ln)\n",
    "    #print('test:', test_data.loc[i,'photoTags'])\n",
    "    #print('train:', train_data.loc[ind,'photoTags'])\n",
    "    #print('-----------------------------')\n",
    "    \n",
    "\n",
    "test_data['lt_predicted'] = predicted_lt\n",
    "test_data['lng_predicted'] = predicted_lng\n",
    "\n",
    "test_data.to_csv(\"predicted_1.csv\", encoding=\"utf-8\")\n",
    "\n",
    "data_predicted = pd.read_csv('predicted_1.csv')\n",
    "\n",
    "# let's calculate the error and save it in a new column \n",
    "lt_error = (data_predicted['lt_predicted'] - data_predicted['latitude'])**(2)\n",
    "ln_error = (data_predicted['lng_predicted'] - data_predicted['longitude'])**(2)\n",
    "er = (lt_error + ln_error)**(0.5)\n",
    "data_predicted['error'] = er\n",
    "\n",
    "# we will see radius of 0.001 km, 0.01 km, 1 km, 10 km , 100 km , 1000 km, 10000 km, 40000 km \n",
    "\n",
    "data_predicted.to_csv(\"predicted_1_error.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(svd_train_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-05, 0.0001, 0.01, 0.1, 1, 10, 100, 400]\n",
      "[0, 0, 8, 131, 359, 3797, 13901, 21200]\n",
      "[0.0, 0.0, 0.00037735849056603772, 0.0061792452830188678, 0.016933962264150944, 0.17910377358490567, 0.65570754716981128, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data_predicted = pd.read_csv('predicted_1.csv')\n",
    "\n",
    "# let's calculate the error and save it in a new column \n",
    "lt_error = (data_predicted['lt_predicted'] - data_predicted['latitude'])**(2)\n",
    "ln_error = (data_predicted['lng_predicted'] - data_predicted['longitude'])**(2)\n",
    "er = (lt_error + ln_error)**(0.5)\n",
    "data_predicted['error'] = er\n",
    "\n",
    "# we will see radius of 0.001 km, 0.01 km, 1 km, 10 km , 100 km , 1000 km, 10000 km, 40000 km \n",
    "\n",
    "radius = [0.00001, 0.0001, 0.01, 0.1, 1, 10, 100, 400]\n",
    "\n",
    "# 1 latitude = 111 km , so we will round it to 100 km\n",
    "answers = []\n",
    "for el in radius: \n",
    "    answers.append(data_predicted['error'][data_predicted['error']<el].count())\n",
    "accuracy = []\n",
    "amount = len(data_predicted)\n",
    "print(radius)\n",
    "print(answers)\n",
    "for i in range(0,8):\n",
    "    accuracy.append(answers[i]/amount)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x143148 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
